{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86176e63-7fcb-4b02-99cf-4fbee800fe7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb00b140-4cff-41c7-a7b2-29c42fe97b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform_v1beta1 as aip_beta\n",
    "\n",
    "from google.cloud.aiplatform import Endpoint, Model\n",
    "from google.api_core.exceptions import InvalidArgument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "265b9e66-11ce-4a6d-a71b-db76dbe8164c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27c42d25-001e-4316-9a70-bd628c0a6a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbtham\n"
     ]
    }
   ],
   "source": [
    "# Get account name\n",
    "import requests\n",
    "gcloud_token = !gcloud auth print-access-token\n",
    "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "account_email = gcloud_tokeninfo['email']\n",
    "#account_name = gcloud_tokeninfo['email'].split('@')[0]\n",
    "account_name = 'cbtham'\n",
    "#print(account_email)\n",
    "print(account_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54302f10-f523-4923-88bb-fa910e4746c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = 'asia-southeast1' # please set here, e.g. us-central1\n",
    "project_id = 'astral-root-443419-b8' # please set here\n",
    "public_repository = 'cbthamdev' # please set here any value to name the artifact registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52a62166-5d38-4bd1-9c7c-951e7a23efec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "private_repository = account_name\n",
    "bucket_url = f\"gs://{account_name}\"\n",
    "\n",
    "nim_model = \"nim:llama3-8b-instruct-1.0.0\"\n",
    "# NIM in NGC\n",
    "ngc_nim_image = \"nvcr.io/nim/meta/llama3-8b-instruct:1.0.0\"\n",
    "# NIM in Artifact Registry\n",
    "public_nim_image = f\"{region}-docker.pkg.dev/{project_id}/{public_repository}/{nim_model}\"\n",
    "private_nim_image = f\"{region}-docker.pkg.dev/{project_id}/{private_repository}/{nim_model}\"\n",
    "\n",
    "va_model_name = \"nim-llama3-8b-instruct\"\n",
    "\n",
    "selected_profile = \"vllm-fp16-tp2\"\n",
    "machine_type = \"g2-standard-24\"\n",
    "accelerator_type = \"NVIDIA_L4\"\n",
    "accelerator_count = 2\n",
    "\n",
    "endpoint_name = va_model_name+\"_endpoint\"\n",
    "payload_model = \"meta/llama3-8b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a267bf20-0d5f-415c-822e-1890e406d8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cbtham/...\n",
      "ServiceException: 409 A Cloud Storage bucket named 'cbtham' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n",
      "Create request issued for: [cbthamdev]\n",
      "Waiting for operation [projects/astral-root-443419-b8/locations/asia-southeast1\n",
      "/operations/47eb6970-5a8d-436b-86a7-2aec3eade69d] to complete...done.          \n",
      "Created repository [cbthamdev].\n",
      "Updated IAM policy for repository [cbthamdev].\n",
      "bindings:\n",
      "- members:\n",
      "  - allUsers\n",
      "  role: roles/artifactregistry.repoAdmin\n",
      "etag: BwYoQJr-8MI=\n",
      "version: 1\n",
      "Create request issued for: [cbtham]\n",
      "Waiting for operation [projects/astral-root-443419-b8/locations/asia-southeast1\n",
      "/operations/da5a9ab2-5203-43b7-bf1c-64aac4b4ed0e] to complete...done.          \n",
      "Created repository [cbtham].\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {region} -p {project_id} {bucket_url}\n",
    "! gcloud artifacts repositories create {public_repository} --repository-format=docker --location={region}\n",
    "! gcloud artifacts repositories add-iam-policy-binding {public_repository} --location={region} --member=allUsers --role=roles/artifactregistry.repoAdmin\n",
    "! gcloud artifacts repositories create {private_repository} --repository-format=docker --location={region}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d00afc15-1bd1-4b98-9e4a-82c37d066a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=project_id, location=region, staging_bucket=bucket_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "997246cf-d2c7-4226-9b11-cc261ece9739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_bash_cmd(cmd):\n",
    "    import subprocess\n",
    "\n",
    "    if isinstance(cmd, str):\n",
    "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=True, text=True)\n",
    "    elif isinstance(cmd, list):\n",
    "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, shell=False, text=True)\n",
    "        \n",
    "    output, error = process.communicate()\n",
    "    if error:\n",
    "        raise Exception(error)\n",
    "    else:\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9797ed54-ca49-4f4e-87e2-803efd69684f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [ai_platform/region].\n",
      "Updated property [core/project].\n",
      "WARNING: Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: asia-southeast1-docker.pkg.dev\n",
      "After update, the following will be written to your Docker config file located \n",
      "at [/home/jupyter/.docker/config.json]:\n",
      " {\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"asia-southeast1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Do you want to continue (Y/n)?  \n",
      "Docker configuration file updated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bash_cmd = f\"\"\"\n",
    "    export region={region}\n",
    "    gcloud config set ai_platform/region {region}\n",
    "    gcloud config set project {project_id}\n",
    "    gcloud auth configure-docker {region}-docker.pkg.dev\n",
    "    \"\"\"\n",
    "run_bash_cmd(bash_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d75b0811-a17c-44a3-8610-ea04dadb7242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NGC_API_KEY = '#_Redacted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e36f6618-0626-430c-9d6a-2235e3e93977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "nvidia-docker2 is already the newest version (2.13.0-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
      "WARNING! Your password will be stored unencrypted in /home/jupyter/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Local NIM cache created\n",
      "\n",
      "NIM image nvcr.io/nim/meta/llama3-8b-instruct:1.0.0 pulled from NGC successfully, running container is\n",
      "Unable to find image 'nvcr.io/nim/meta/llama3-8b-instruct:1.0.0' locally\n",
      "1.0.0: Pulling from nim/meta/llama3-8b-instruct\n",
      "5e8117c0bd28: Pulling fs layer\n",
      "d67fcc6ef577: Pulling fs layer\n",
      "47ee674c5713: Pulling fs layer\n",
      "63daa0e64b30: Pulling fs layer\n",
      "d9d9aecefab5: Pulling fs layer\n",
      "d71f46a15657: Pulling fs layer\n",
      "054e2ffff644: Pulling fs layer\n",
      "7d3cd81654d5: Pulling fs layer\n",
      "dca613dca886: Pulling fs layer\n",
      "0fdcdcda3b2e: Pulling fs layer\n",
      "af7b4f7dc15a: Pulling fs layer\n",
      "6d101782f66c: Pulling fs layer\n",
      "e8427cb13897: Pulling fs layer\n",
      "d71f46a15657: Waiting\n",
      "054e2ffff644: Waiting\n",
      "7d3cd81654d5: Waiting\n",
      "0fdcdcda3b2e: Waiting\n",
      "dca613dca886: Waiting\n",
      "6d101782f66c: Waiting\n",
      "63daa0e64b30: Waiting\n",
      "d9d9aecefab5: Waiting\n",
      "e8427cb13897: Waiting\n",
      "de05b029a5a2: Pulling fs layer\n",
      "3d72a2698104: Pulling fs layer\n",
      "aeff973c2191: Pulling fs layer\n",
      "de05b029a5a2: Waiting\n",
      "3d72a2698104: Waiting\n",
      "85d7d3ff0cca: Pulling fs layer\n",
      "5996430251dd: Pulling fs layer\n",
      "314dc83fdfc2: Pulling fs layer\n",
      "5cef8f59ae9a: Pulling fs layer\n",
      "aeff973c2191: Waiting\n",
      "85d7d3ff0cca: Waiting\n",
      "927db4ce3e96: Pulling fs layer\n",
      "cbe4a04f4491: Pulling fs layer\n",
      "60f1a03c0955: Pulling fs layer\n",
      "67c1bb2b1aac: Pulling fs layer\n",
      "f16f7b821143: Pulling fs layer\n",
      "5cef8f59ae9a: Waiting\n",
      "9be4fff0cd1a: Pulling fs layer\n",
      "927db4ce3e96: Waiting\n",
      "cbe4a04f4491: Waiting\n",
      "60f1a03c0955: Waiting\n",
      "9be4fff0cd1a: Waiting\n",
      "67c1bb2b1aac: Waiting\n",
      "f16f7b821143: Waiting\n",
      "d67fcc6ef577: Verifying Checksum\n",
      "d67fcc6ef577: Download complete\n",
      "5e8117c0bd28: Verifying Checksum\n",
      "5e8117c0bd28: Download complete\n",
      "47ee674c5713: Verifying Checksum\n",
      "47ee674c5713: Download complete\n",
      "63daa0e64b30: Verifying Checksum\n",
      "63daa0e64b30: Download complete\n",
      "d9d9aecefab5: Verifying Checksum\n",
      "d9d9aecefab5: Download complete\n",
      "5e8117c0bd28: Pull complete\n",
      "d67fcc6ef577: Pull complete\n",
      "47ee674c5713: Pull complete\n",
      "63daa0e64b30: Pull complete\n",
      "d9d9aecefab5: Pull complete\n",
      "d71f46a15657: Verifying Checksum\n",
      "d71f46a15657: Download complete\n",
      "d71f46a15657: Pull complete\n",
      "dca613dca886: Verifying Checksum\n",
      "dca613dca886: Download complete\n",
      "0fdcdcda3b2e: Verifying Checksum\n",
      "0fdcdcda3b2e: Download complete\n",
      "054e2ffff644: Verifying Checksum\n",
      "054e2ffff644: Download complete\n",
      "6d101782f66c: Download complete\n",
      "e8427cb13897: Download complete\n",
      "de05b029a5a2: Verifying Checksum\n",
      "de05b029a5a2: Download complete\n",
      "3d72a2698104: Verifying Checksum\n",
      "3d72a2698104: Download complete\n",
      "aeff973c2191: Verifying Checksum\n",
      "aeff973c2191: Download complete\n",
      "85d7d3ff0cca: Verifying Checksum\n",
      "85d7d3ff0cca: Download complete\n",
      "7d3cd81654d5: Verifying Checksum\n",
      "7d3cd81654d5: Download complete\n",
      "5996430251dd: Verifying Checksum\n",
      "5996430251dd: Download complete\n",
      "314dc83fdfc2: Verifying Checksum\n",
      "314dc83fdfc2: Download complete\n",
      "927db4ce3e96: Download complete\n",
      "5cef8f59ae9a: Verifying Checksum\n",
      "5cef8f59ae9a: Download complete\n",
      "cbe4a04f4491: Verifying Checksum\n",
      "cbe4a04f4491: Download complete\n",
      "60f1a03c0955: Download complete\n",
      "67c1bb2b1aac: Verifying Checksum\n",
      "67c1bb2b1aac: Download complete\n",
      "f16f7b821143: Verifying Checksum\n",
      "f16f7b821143: Download complete\n",
      "9be4fff0cd1a: Verifying Checksum\n",
      "9be4fff0cd1a: Download complete\n",
      "af7b4f7dc15a: Verifying Checksum\n",
      "af7b4f7dc15a: Download complete\n",
      "054e2ffff644: Pull complete\n",
      "7d3cd81654d5: Pull complete\n",
      "dca613dca886: Pull complete\n",
      "0fdcdcda3b2e: Pull complete\n",
      "af7b4f7dc15a: Pull complete\n",
      "6d101782f66c: Pull complete\n",
      "e8427cb13897: Pull complete\n",
      "de05b029a5a2: Pull complete\n",
      "3d72a2698104: Pull complete\n",
      "aeff973c2191: Pull complete\n",
      "85d7d3ff0cca: Pull complete\n",
      "5996430251dd: Pull complete\n",
      "314dc83fdfc2: Pull complete\n",
      "5cef8f59ae9a: Pull complete\n",
      "927db4ce3e96: Pull complete\n",
      "cbe4a04f4491: Pull complete\n",
      "60f1a03c0955: Pull complete\n",
      "67c1bb2b1aac: Pull complete\n",
      "f16f7b821143: Pull complete\n",
      "9be4fff0cd1a: Pull complete\n",
      "Digest: sha256:7fe6071923b547edd9fba87c891a362ea0b4a88794b8a422d63127e54caa6ef7\n",
      "Status: Downloaded newer image for nvcr.io/nim/meta/llama3-8b-instruct:1.0.0\n",
      "2eaebdced2bfd73bc3167e134b35d7d851f70e8969320a3312c776c74aedeee3\n",
      "\n",
      "The push refers to repository [asia-southeast1-docker.pkg.dev/astral-root-443419-b8/cbthamdev/nim]\n",
      "d6e3d1329879: Preparing\n",
      "c6efc285869e: Preparing\n",
      "2decb5c4804e: Preparing\n",
      "39111a8a9ded: Preparing\n",
      "ec561d7e6811: Preparing\n",
      "64698ac07231: Preparing\n",
      "086db532493b: Preparing\n",
      "96ffa74d03cf: Preparing\n",
      "029474febabe: Preparing\n",
      "591935392904: Preparing\n",
      "22ba5c2fc887: Preparing\n",
      "9034ce09b708: Preparing\n",
      "034e11c3e122: Preparing\n",
      "80e3915a53fa: Preparing\n",
      "2c9f8812e444: Preparing\n",
      "e9878d508160: Preparing\n",
      "e6a2e7dc7c95: Preparing\n",
      "57c2269cdf89: Preparing\n",
      "aa02d223d9df: Preparing\n",
      "17bbf87bba59: Preparing\n",
      "3970fd90d179: Preparing\n",
      "bae3163c64b8: Preparing\n",
      "f0fc8a1ca0cb: Preparing\n",
      "90efea7ecd8e: Preparing\n",
      "b6a0147bcf99: Preparing\n",
      "8ceb9643fb36: Preparing\n",
      "64698ac07231: Waiting\n",
      "2c9f8812e444: Waiting\n",
      "e9878d508160: Waiting\n",
      "e6a2e7dc7c95: Waiting\n",
      "57c2269cdf89: Waiting\n",
      "aa02d223d9df: Waiting\n",
      "17bbf87bba59: Waiting\n",
      "3970fd90d179: Waiting\n",
      "bae3163c64b8: Waiting\n",
      "f0fc8a1ca0cb: Waiting\n",
      "90efea7ecd8e: Waiting\n",
      "b6a0147bcf99: Waiting\n",
      "8ceb9643fb36: Waiting\n",
      "086db532493b: Waiting\n",
      "96ffa74d03cf: Waiting\n",
      "029474febabe: Waiting\n",
      "591935392904: Waiting\n",
      "22ba5c2fc887: Waiting\n",
      "9034ce09b708: Waiting\n",
      "034e11c3e122: Waiting\n",
      "80e3915a53fa: Waiting\n",
      "2decb5c4804e: Pushed\n",
      "c6efc285869e: Pushed\n",
      "d6e3d1329879: Pushed\n",
      "ec561d7e6811: Pushed\n",
      "39111a8a9ded: Pushed\n",
      "64698ac07231: Pushed\n",
      "029474febabe: Pushed\n",
      "96ffa74d03cf: Pushed\n",
      "591935392904: Pushed\n",
      "22ba5c2fc887: Pushed\n",
      "9034ce09b708: Pushed\n",
      "034e11c3e122: Pushed\n",
      "80e3915a53fa: Pushed\n",
      "2c9f8812e444: Pushed\n",
      "086db532493b: Pushed\n",
      "e6a2e7dc7c95: Pushed\n",
      "3970fd90d179: Pushed\n",
      "bae3163c64b8: Pushed\n",
      "f0fc8a1ca0cb: Pushed\n",
      "90efea7ecd8e: Pushed\n",
      "b6a0147bcf99: Pushed\n",
      "8ceb9643fb36: Layer already exists\n",
      "e9878d508160: Pushed\n",
      "57c2269cdf89: Pushed\n",
      "17bbf87bba59: Pushed\n",
      "aa02d223d9df: Pushed\n",
      "llama3-8b-instruct-1.0.0: digest: sha256:721cbfd4178672ab7b19941e52b88efd3502350cd1f737eae965a142432c9e6a size: 5764\n",
      "\n",
      "NIM image nvcr.io/nim/meta/llama3-8b-instruct:1.0.0 pushed to Artifact Registry asia-southeast1-docker.pkg.dev/astral-root-443419-b8/cbthamdev/nim:llama3-8b-instruct-1.0.0 successfully\n",
      "The push refers to repository [asia-southeast1-docker.pkg.dev/astral-root-443419-b8/cbtham/nim]\n",
      "d6e3d1329879: Preparing\n",
      "c6efc285869e: Preparing\n",
      "2decb5c4804e: Preparing\n",
      "39111a8a9ded: Preparing\n",
      "ec561d7e6811: Preparing\n",
      "64698ac07231: Preparing\n",
      "086db532493b: Preparing\n",
      "96ffa74d03cf: Preparing\n",
      "029474febabe: Preparing\n",
      "591935392904: Preparing\n",
      "22ba5c2fc887: Preparing\n",
      "9034ce09b708: Preparing\n",
      "034e11c3e122: Preparing\n",
      "80e3915a53fa: Preparing\n",
      "2c9f8812e444: Preparing\n",
      "e9878d508160: Preparing\n",
      "e6a2e7dc7c95: Preparing\n",
      "57c2269cdf89: Preparing\n",
      "aa02d223d9df: Preparing\n",
      "17bbf87bba59: Preparing\n",
      "3970fd90d179: Preparing\n",
      "bae3163c64b8: Preparing\n",
      "f0fc8a1ca0cb: Preparing\n",
      "90efea7ecd8e: Preparing\n",
      "b6a0147bcf99: Preparing\n",
      "8ceb9643fb36: Preparing\n",
      "2c9f8812e444: Waiting\n",
      "e9878d508160: Waiting\n",
      "e6a2e7dc7c95: Waiting\n",
      "57c2269cdf89: Waiting\n",
      "591935392904: Waiting\n",
      "64698ac07231: Waiting\n",
      "22ba5c2fc887: Waiting\n",
      "086db532493b: Waiting\n",
      "9034ce09b708: Waiting\n",
      "96ffa74d03cf: Waiting\n",
      "029474febabe: Waiting\n",
      "034e11c3e122: Waiting\n",
      "80e3915a53fa: Waiting\n",
      "aa02d223d9df: Waiting\n",
      "bae3163c64b8: Waiting\n",
      "17bbf87bba59: Waiting\n",
      "f0fc8a1ca0cb: Waiting\n",
      "3970fd90d179: Waiting\n",
      "90efea7ecd8e: Waiting\n",
      "b6a0147bcf99: Waiting\n",
      "8ceb9643fb36: Waiting\n",
      "ec561d7e6811: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "d6e3d1329879: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "39111a8a9ded: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "c6efc285869e: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "2decb5c4804e: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "086db532493b: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "64698ac07231: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "96ffa74d03cf: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "029474febabe: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "591935392904: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "22ba5c2fc887: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "9034ce09b708: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "034e11c3e122: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "80e3915a53fa: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "2c9f8812e444: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "e9878d508160: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "e6a2e7dc7c95: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "57c2269cdf89: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "aa02d223d9df: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "17bbf87bba59: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "3970fd90d179: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "bae3163c64b8: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "f0fc8a1ca0cb: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "90efea7ecd8e: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "b6a0147bcf99: Mounted from astral-root-443419-b8/cbthamdev/nim\n",
      "8ceb9643fb36: Layer already exists\n",
      "llama3-8b-instruct-1.0.0: digest: sha256:721cbfd4178672ab7b19941e52b88efd3502350cd1f737eae965a142432c9e6a size: 5764\n",
      "\n",
      "NIM image asia-southeast1-docker.pkg.dev/astral-root-443419-b8/cbthamdev/nim:llama3-8b-instruct-1.0.0 pushed to Artifact Registry asia-southeast1-docker.pkg.dev/astral-root-443419-b8/cbtham/nim:llama3-8b-instruct-1.0.0 successfully\n"
     ]
    }
   ],
   "source": [
    "# Login to NGC\n",
    "from pathlib import Path\n",
    "container_name=\"llama3-8B-Instruct\"\n",
    "local_nim_cache=str(Path(\".cache/nim\").absolute())\n",
    "\n",
    "bash_cmd = f\"\"\"\n",
    "    sudo apt-get install -y nvidia-docker2\n",
    "    export NGC_API_KEY={NGC_API_KEY}\n",
    "    echo \"export NGC_API_KEY={NGC_API_KEY}\" >> ~/.bashrc\n",
    "    echo \"$NGC_API_KEY\" | docker login nvcr.io --username '$oauthtoken' --password-stdin\n",
    "\n",
    "    export LOCAL_NIM_CACHE={local_nim_cache}\n",
    "    mkdir -p \"$LOCAL_NIM_CACHE\"\n",
    "    echo \"Local NIM cache created\"\n",
    "    \"\"\"\n",
    "\n",
    "run_bash_cmd(bash_cmd)\n",
    "\n",
    "# Pull NIM image from NGC and run container\n",
    "docker_cmd = [\n",
    "    \"docker\", \"run\", \"-d\", \"--rm\",\n",
    "    f\"--name={container_name}\",\n",
    "    \"--gpus\", \"all\",\n",
    "    \"-e\", f\"{NGC_API_KEY}\",\n",
    "    \"-v\", f\"{local_nim_cache}:/opt/nim/.cache\",\n",
    "    \"-p\", \"8000:8000\",\n",
    "    ngc_nim_image\n",
    "]\n",
    "\n",
    "print(f\"NIM image {ngc_nim_image} pulled from NGC successfully, running container is\")\n",
    "run_bash_cmd(docker_cmd)\n",
    "\n",
    "# Push NIM image to public AR repository\n",
    "bash_cmd = f\"\"\"\n",
    "    docker tag {ngc_nim_image} {public_nim_image}\n",
    "\n",
    "    docker push {public_nim_image}\n",
    "    \"\"\"\n",
    "\n",
    "run_bash_cmd(bash_cmd)\n",
    "print(f\"NIM image {ngc_nim_image} pushed to Artifact Registry {public_nim_image} successfully\")\n",
    "\n",
    "# Optional\n",
    "# Push NIM image to private AR repository\n",
    "bash_cmd = f\"\"\"\n",
    "    docker tag {public_nim_image} {private_nim_image}\n",
    "\n",
    "    docker push {private_nim_image}\n",
    "    \"\"\"\n",
    "\n",
    "run_bash_cmd(bash_cmd)\n",
    "print(f\"NIM image {public_nim_image} pushed to Artifact Registry {private_nim_image} successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7d0407e-1f89-4ac9-bcc3-9568f0e86a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "== NVIDIA Inference Microservice LLM NIM ==\n",
      "===========================================\n",
      "\n",
      "NVIDIA Inference Microservice LLM NIM Version 1.0.0\n",
      "Model: nim/meta/llama3-8b-instruct\n",
      "\n",
      "Container image Copyright (c) 2016-2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "This NIM container is governed by the NVIDIA AI Product Agreement here:\n",
      "https://www.nvidia.com/en-us/data-center/products/nvidia-ai-enterprise/eula/.\n",
      "A copy of this license can be found under /opt/nim/LICENSE.\n",
      "\n",
      "The use of this model is governed by the AI Foundation Models Community License\n",
      "here: https://docs.nvidia.com/ai-foundation-models-community-license.pdf.\n",
      "\n",
      "ADDITIONAL INFORMATION: Meta Llama 3 Community License, Built with Meta Llama 3. \n",
      "A copy of the Llama 3 license can be found under /opt/nim/MODEL_LICENSE.\n",
      "\n",
      "2024-12-02 03:00:39,550 [INFO] PyTorch version 2.2.2 available.\n",
      "2024-12-02 03:00:40,129 [WARNING] [TRT-LLM] [W] Logger level already set from environment. Discard new verbosity: error\n",
      "2024-12-02 03:00:40,129 [INFO] [TRT-LLM] [I] Starting TensorRT-LLM init.\n",
      "2024-12-02 03:00:40,237 [INFO] [TRT-LLM] [I] TensorRT-LLM inited.\n",
      "[TensorRT-LLM] TensorRT-LLM version: 0.10.1.dev2024053000\n",
      "INFO 12-02 03:00:41.329 api_server.py:489] NIM LLM API version 1.0.0\n",
      "INFO 12-02 03:00:41.331 ngc_profile.py:217] Running NIM without LoRA. Only looking for compatible profiles that do not support LoRA.\n",
      "INFO 12-02 03:00:41.331 ngc_profile.py:219] Detected 1 compatible profile(s).\n",
      "ERROR 12-02 03:00:41.332 utils.py:21] Profile 'vllm-fp16-tp2' is incompatible with detected hardware. Please check the system information below and select a compatible profile.\n",
      "SYSTEM INFO\n",
      "- Free GPUs:\n",
      "  -  [27b8:10de] (0) NVIDIA L4 [current utilization: 2%]\n"
     ]
    }
   ],
   "source": [
    "# Run NIM container\n",
    "! docker run -it --rm --name={container_name} \\\n",
    "  --runtime=nvidia \\\n",
    "  --gpus all \\\n",
    "  --shm-size=16GB \\\n",
    "  -e NGC_API_KEY={NGC_API_KEY} \\\n",
    "  -e NIM_MODEL_PROFILE={selected_profile} \\\n",
    "  -v {local_nim_cache}\":/opt/nim/.cache\" \\\n",
    "  -u $(id -u) \\\n",
    "  -p 8000:8000 \\\n",
    "  {private_nim_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c72a388d-2fbd-45c7-aa0e-bbffdafb8230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                           TAG                        IMAGE ID       CREATED        SIZE\n",
      "asia-southeast1-docker.pkg.dev/astral-root-443419-b8/cbtham/nim      llama3-8b-instruct-1.0.0   3cb29b0d79e6   6 months ago   12.5GB\n",
      "asia-southeast1-docker.pkg.dev/astral-root-443419-b8/cbthamdev/nim   llama3-8b-instruct-1.0.0   3cb29b0d79e6   6 months ago   12.5GB\n",
      "nvcr.io/nim/meta/llama3-8b-instruct                                  1.0.0                      3cb29b0d79e6   6 months ago   12.5GB\n"
     ]
    }
   ],
   "source": [
    "! docker images"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
